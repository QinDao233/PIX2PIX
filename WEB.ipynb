{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: 'datasets/facades\\\\val'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 402\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages)\n\u001b[0;32m    401\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoints/pix2pix_epoch_100.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# 替换为你的模型路径\u001b[39;00m\n\u001b[1;32m--> 402\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mAlignedDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatasets/facades\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    404\u001b[0m demo \u001b[38;5;241m=\u001b[39m create_interface(model_path, dataset)\n\u001b[0;32m    405\u001b[0m port \u001b[38;5;241m=\u001b[39m find_available_port()\n",
      "Cell \u001b[1;32mIn[1], line 387\u001b[0m, in \u001b[0;36mAlignedDataset.__init__\u001b[1;34m(self, root, phase)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, root, phase\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, phase)\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m))]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: 'datasets/facades\\\\val'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import gradio as gr\n",
    "import functools\n",
    "import socket\n",
    "\n",
    "\n",
    "# 设备配置\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "\n",
    "# 1. 模型定义（严格按照原始pix2pix架构）\n",
    "class UnetSkipConnectionBlock(nn.Module):\n",
    "    def __init__(self, outer_nc, inner_nc, input_nc=None,\n",
    "                 submodule=None, outermost=False, innermost=False, \n",
    "                 norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
    "        super(UnetSkipConnectionBlock, self).__init__()\n",
    "        self.outermost = outermost\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "            \n",
    "        if input_nc is None:\n",
    "            input_nc = outer_nc\n",
    "            \n",
    "        downconv = nn.Conv2d(input_nc, inner_nc, kernel_size=4,\n",
    "                             stride=2, padding=1, bias=use_bias)\n",
    "        downrelu = nn.LeakyReLU(0.2, True)\n",
    "        downnorm = norm_layer(inner_nc)\n",
    "        uprelu = nn.ReLU(True)\n",
    "        upnorm = norm_layer(outer_nc)\n",
    "\n",
    "        if outermost:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1)\n",
    "            down = [downconv]\n",
    "            up = [uprelu, upconv, nn.Tanh()]\n",
    "            model = down + [submodule] + up\n",
    "        elif innermost:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1, bias=use_bias)\n",
    "            down = [downrelu, downconv]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            model = down + up\n",
    "        else:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1, bias=use_bias)\n",
    "            down = [downrelu, downconv, downnorm]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "\n",
    "            if use_dropout:\n",
    "                model = down + [submodule] + up + [nn.Dropout(0.5)]\n",
    "            else:\n",
    "                model = down + [submodule] + up\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.outermost:\n",
    "            return self.model(x)\n",
    "        else:\n",
    "            return torch.cat([x, self.model(x)], 1)\n",
    "\n",
    "\n",
    "class UnetGenerator(nn.Module):\n",
    "    \"\"\"严格按照原始pix2pix的U-Net结构实现\"\"\"\n",
    "    def __init__(self, input_nc=3, output_nc=3, num_downs=8, ngf=64,\n",
    "                 norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
    "        super(UnetGenerator, self).__init__()\n",
    "        \n",
    "        # 构建U-Net结构\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, \n",
    "                                            submodule=None, norm_layer=norm_layer, innermost=True)\n",
    "        \n",
    "        # 中间层\n",
    "        for i in range(num_downs - 5):\n",
    "            unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, \n",
    "                                                submodule=unet_block, norm_layer=norm_layer, use_dropout=use_dropout)\n",
    "        \n",
    "        # 逐渐减少通道数\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 4, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 2, ngf * 4, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock(ngf, ngf * 2, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        \n",
    "        # 最外层\n",
    "        unet_block = UnetSkipConnectionBlock(output_nc, ngf, input_nc=input_nc, \n",
    "                                           submodule=unet_block, outermost=True, norm_layer=norm_layer)\n",
    "        \n",
    "        self.model = unet_block\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "\n",
    "\n",
    "# 2. 辅助函数\n",
    "def find_available_port(start_port=7868, end_port=7968):\n",
    "    for port in range(start_port, end_port + 1):\n",
    "        try:\n",
    "            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "                s.bind(('0.0.0.0', port))\n",
    "                return port\n",
    "        except OSError:\n",
    "            continue\n",
    "    raise OSError(f\"无法在范围 {start_port}-{end_port} 内找到可用端口\")\n",
    "\n",
    "\n",
    "def tensor2im(input_image, imtype=np.uint8):\n",
    "    \"\"\"增强版：处理各种格式的图像转换\"\"\"\n",
    "    try:\n",
    "        if isinstance(input_image, torch.Tensor):\n",
    "            # 处理PyTorch张量\n",
    "            image_tensor = input_image.data.cpu().float().numpy()\n",
    "            \n",
    "            # 调试信息\n",
    "            print(f\"张量形状: {image_tensor.shape}\")\n",
    "            \n",
    "            # 移除batch维度\n",
    "            if image_tensor.ndim == 4:\n",
    "                image_tensor = image_tensor[0]\n",
    "                \n",
    "            # 转换通道维度：(C, H, W) -> (H, W, C)\n",
    "            if image_tensor.shape[0] in [1, 3]:\n",
    "                image_tensor = np.transpose(image_tensor, (1, 2, 0))\n",
    "                \n",
    "            # 处理单通道图像：复制为三通道\n",
    "            if image_tensor.shape[-1] == 1:\n",
    "                image_tensor = np.repeat(image_tensor, 3, axis=-1)\n",
    "                \n",
    "            # 归一化到[0, 255]\n",
    "            image_tensor = (image_tensor + 1) / 2.0 * 255.0\n",
    "            image_tensor = np.clip(image_tensor, 0, 255)\n",
    "            \n",
    "            return image_tensor.astype(imtype)\n",
    "        \n",
    "        # 处理numpy数组\n",
    "        if isinstance(input_image, np.ndarray):\n",
    "            # 调试信息\n",
    "            print(f\"numpy数组形状: {input_image.shape}\")\n",
    "            \n",
    "            # 处理单通道图像\n",
    "            if input_image.ndim == 2:\n",
    "                return np.repeat(input_image[:, :, np.newaxis], 3, axis=2).astype(imtype)\n",
    "            if input_image.ndim == 3 and input_image.shape[-1] == 1:\n",
    "                return np.repeat(input_image, 3, axis=2).astype(imtype)\n",
    "            return input_image.astype(imtype)\n",
    "            \n",
    "        # 处理PIL图像\n",
    "        img = input_image.convert('RGB')\n",
    "        return np.array(img).astype(imtype)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"张量转换错误: {e}\")\n",
    "        # 打印详细的错误堆栈\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return np.zeros((256, 256, 3), dtype=imtype)\n",
    "\n",
    "\n",
    "def preprocess_image(image, size=(256, 256)):\n",
    "    \"\"\"确保所有输入图像都是RGB格式，形状正确\"\"\"\n",
    "    if image is None:\n",
    "        return None\n",
    "        \n",
    "    # 转换为PIL图像\n",
    "    if isinstance(image, np.ndarray):\n",
    "        print(f\"预处理前numpy数组形状: {image.shape}\")\n",
    "        # 处理单通道numpy数组\n",
    "        if image.ndim == 2 or (image.ndim == 3 and image.shape[-1] == 1):\n",
    "            image = Image.fromarray(image.squeeze(), mode='L').convert('RGB')\n",
    "        else:\n",
    "            image = Image.fromarray(image)\n",
    "    \n",
    "    # 确保是RGB格式\n",
    "    if image.mode != 'RGB':\n",
    "        print(f\"转换图像模式从 {image.mode} 到 RGB\")\n",
    "        image = image.convert('RGB')\n",
    "    \n",
    "    # 调整大小并居中裁剪\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(size, Image.BICUBIC),\n",
    "        transforms.CenterCrop(size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    \n",
    "    # 应用转换并返回\n",
    "    tensor = transform(image)\n",
    "    print(f\"预处理后张量形状: {tensor.shape}\")\n",
    "    return tensor.unsqueeze(0)\n",
    "\n",
    "\n",
    "# 3. 模型加载（改进权重匹配和调试信息）\n",
    "def load_model(model_path):\n",
    "    \"\"\"严格按照原始pix2pix的U-Net结构加载模型\"\"\"\n",
    "    try:\n",
    "        # 创建模型（严格匹配原始pix2pix架构）\n",
    "        model = UnetGenerator(\n",
    "            input_nc=3,\n",
    "            output_nc=3,\n",
    "            num_downs=8,\n",
    "            ngf=64,  # 关键：与训练时ngf=64匹配\n",
    "            norm_layer=functools.partial(nn.BatchNorm2d, affine=True, track_running_stats=True),\n",
    "            use_dropout=False\n",
    "        )\n",
    "        \n",
    "        # 打印模型结构用于调试\n",
    "        print(\"模型结构:\")\n",
    "        print(model)\n",
    "        \n",
    "        # 加载权重\n",
    "        print(f\"从 {model_path} 加载模型权重...\")\n",
    "        checkpoint = torch.load(model_path, map_location=device, weights_only=True)\n",
    "        \n",
    "        # 尝试不同的权重键名\n",
    "        possible_keys = ['generator_state_dict', 'netG', 'state_dict', 'model']\n",
    "        gen_weights = None\n",
    "        \n",
    "        for key in possible_keys:\n",
    "            if key in checkpoint:\n",
    "                gen_weights = checkpoint[key]\n",
    "                print(f\"从检查点中找到权重键: {key}\")\n",
    "                break\n",
    "        \n",
    "        # 如果没找到特定键，尝试直接使用检查点\n",
    "        if gen_weights is None:\n",
    "            gen_weights = checkpoint\n",
    "            print(\"使用整个检查点作为权重\")\n",
    "        \n",
    "        # 清理权重键名（移除可能的前缀）\n",
    "        cleaned_weights = {}\n",
    "        prefixes = ['module.', 'netG.', 'model.']\n",
    "        \n",
    "        for k, v in gen_weights.items():\n",
    "            # 尝试移除常见前缀\n",
    "            cleaned_k = k\n",
    "            for prefix in prefixes:\n",
    "                if cleaned_k.startswith(prefix):\n",
    "                    cleaned_k = cleaned_k[len(prefix):]\n",
    "                    break\n",
    "            cleaned_weights[cleaned_k] = v\n",
    "        \n",
    "        # 非严格加载（仅匹配可兼容的层）\n",
    "        model_dict = model.state_dict()\n",
    "        matched_weights = {}\n",
    "        unmatched_weights = {}\n",
    "        \n",
    "        for k, v in cleaned_weights.items():\n",
    "            if k in model_dict and v.shape == model_dict[k].shape:\n",
    "                matched_weights[k] = v\n",
    "            else:\n",
    "                unmatched_weights[k] = v\n",
    "        \n",
    "        print(f\"匹配的权重: {len(matched_weights)}/{len(model_dict)}\")\n",
    "        print(f\"未匹配的权重: {len(unmatched_weights)}\")\n",
    "        \n",
    "        # 打印未匹配的权重用于调试\n",
    "        if len(unmatched_weights) > 0:\n",
    "            print(\"未匹配的权重:\")\n",
    "            for k in unmatched_weights:\n",
    "                if k in model_dict:\n",
    "                    print(f\"  {k}: 形状不匹配 - 权重形状 {unmatched_weights[k].shape}, 模型期望 {model_dict[k].shape}\")\n",
    "                else:\n",
    "                    print(f\"  {k}: 模型中不存在此键\")\n",
    "        \n",
    "        # 更新模型权重\n",
    "        model_dict.update(matched_weights)\n",
    "        model.load_state_dict(model_dict, strict=False)\n",
    "        \n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        print(f\"成功加载模型（匹配 {len(matched_weights)}/{len(model_dict)} 层）\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"加载模型失败: {e}\")\n",
    "        # 打印详细的错误堆栈\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "# 4. 生成与界面逻辑\n",
    "def generate_image(input_image, model_path, dataset=None, dataset_index=None):\n",
    "    try:\n",
    "        print(\"\\n===== 开始生成图像 =====\")\n",
    "        \n",
    "        # 加载模型\n",
    "        model = load_model(model_path)\n",
    "        if model is None:\n",
    "            return None, None, None, \"模型加载失败（结构与权重不兼容）\"\n",
    "        \n",
    "        # 处理输入\n",
    "        if input_image is not None:\n",
    "            # 打印输入图像信息用于调试\n",
    "            if isinstance(input_image, np.ndarray):\n",
    "                print(f\"输入图像类型: numpy数组, 形状: {input_image.shape}, 数据类型: {input_image.dtype}\")\n",
    "            elif isinstance(input_image, Image.Image):\n",
    "                print(f\"输入图像类型: PIL图像, 模式: {input_image.mode}, 大小: {input_image.size}\")\n",
    "            \n",
    "            input_tensor = preprocess_image(input_image)\n",
    "            print(f\"输入张量形状: {input_tensor.shape}\")\n",
    "        else:\n",
    "            if dataset is None or dataset_index is None:\n",
    "                return None, None, None, \"请上传图像或选择示例\"\n",
    "            data = dataset[int(dataset_index)]\n",
    "            input_tensor = data['A'].unsqueeze(0)\n",
    "            print(f\"从数据集中获取的输入张量形状: {input_tensor.shape}\")\n",
    "        \n",
    "        # 生成图像\n",
    "        with torch.no_grad():\n",
    "            print(\"开始模型推理...\")\n",
    "            output_tensor = model(input_tensor.to(device))\n",
    "            print(f\"输出张量形状: {output_tensor.shape}\")\n",
    "        \n",
    "        # 转换为图像\n",
    "        input_img = Image.fromarray(tensor2im(input_tensor))\n",
    "        gen_img = Image.fromarray(tensor2im(output_tensor))\n",
    "        \n",
    "        # 获取真实图像\n",
    "        real_img = Image.new('RGB', (256, 256), color='gray')\n",
    "        if dataset and dataset_index is not None:\n",
    "            data = dataset[int(dataset_index)]\n",
    "            real_img = Image.fromarray(tensor2im(data['B']))\n",
    "        \n",
    "        print(\"===== 图像生成成功 =====\")\n",
    "        return input_img, gen_img, real_img, f\"生成成功（匹配 {len(model.state_dict())//2}/{len(model.state_dict())} 层）\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"生成图像时出错: {e}\")\n",
    "        # 打印详细的错误堆栈\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None, None, f\"错误: {str(e)}\"\n",
    "\n",
    "\n",
    "def create_interface(model_path, dataset=None):\n",
    "    with gr.Blocks(title=\"草图转真实图像\") as demo:\n",
    "        gr.Markdown(\"# 🎨 草图转建筑图像\")\n",
    "        gr.Markdown(\"左：输入草图 | 中：生成图像 | 右：真实图像\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                input_img = gr.Image(label=\"输入草图\", type=\"pil\")\n",
    "                if dataset and len(dataset) > 0:\n",
    "                    idx_slider = gr.Slider(0, min(50, len(dataset)-1), 0, step=1, label=\"示例索引\")\n",
    "                else:\n",
    "                    idx_slider = None\n",
    "                gen_btn = gr.Button(\"生成图像\", variant=\"primary\")\n",
    "                status = gr.Textbox(label=\"状态\", value=\"就绪\")\n",
    "            \n",
    "            with gr.Column(scale=3):\n",
    "                with gr.Row():\n",
    "                    input_out = gr.Image(label=\"输入\")\n",
    "                    gen_out = gr.Image(label=\"生成\")\n",
    "                    real_out = gr.Image(label=\"真实\")\n",
    "        \n",
    "        # 绑定事件\n",
    "        if idx_slider is not None:\n",
    "            gen_btn.click(\n",
    "                fn=lambda img, idx: generate_image(img, model_path, dataset, idx),\n",
    "                inputs=[input_img, idx_slider],\n",
    "                outputs=[input_out, gen_out, real_out, status]\n",
    "            )\n",
    "        else:\n",
    "            gen_btn.click(\n",
    "                fn=lambda img: generate_image(img, model_path),\n",
    "                inputs=[input_img],\n",
    "                outputs=[input_out, gen_out, real_out, status]\n",
    "            )\n",
    "    \n",
    "    return demo\n",
    "\n",
    "\n",
    "# 5. 主函数\n",
    "if __name__ == \"__main__\":\n",
    "    class AlignedDataset:\n",
    "        def __init__(self, root, phase='val'):\n",
    "            self.root = os.path.join(root, phase)\n",
    "            self.images = [f for f in os.listdir(self.root) if f.endswith(('.png', '.jpg'))]\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            img = Image.open(os.path.join(self.root, self.images[idx])).convert('RGB')\n",
    "            w, h = img.size\n",
    "            w2 = w // 2\n",
    "            return {\n",
    "                'A': transforms.ToTensor()(img.crop((w2, 0, w, h))),  # 右侧草图\n",
    "                'B': transforms.ToTensor()(img.crop((0, 0, w2, h)))   # 左侧真实\n",
    "            }\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.images)\n",
    "    \n",
    "    model_path = \"checkpoints/pix2pix_epoch_100.pth\"  # 替换为你的模型路径\n",
    "    dataset = AlignedDataset(root=\"datasets/facades\", phase=\"val\")\n",
    "    \n",
    "    demo = create_interface(model_path, dataset)\n",
    "    port = find_available_port()\n",
    "    demo.launch(server_name=\"0.0.0.0\", server_port=port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
